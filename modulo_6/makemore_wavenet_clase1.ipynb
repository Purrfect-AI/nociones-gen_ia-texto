{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a42d5192-bf84-4091-bde9-85e2f0b6e7f6",
   "metadata": {},
   "source": [
    "# Makemore y wavenet\n",
    "## Código inicial..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002a033b-9638-4ba5-8aed-265a65b0dd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d6b28f-3584-4645-87aa-82fcafc5a99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import idna\n",
    "\n",
    "# def utf8_to_punycode(text: str) -> str:\n",
    "#     \"\"\"Encodes a UTF-8 string to its Punycode representation.\"\"\"\n",
    "#     return idna.encode(text).decode('ascii')\n",
    "\n",
    "def punyencode(text: str) -> str:\n",
    "    \"\"\"Encodes a UTF-8 string to its Punycode representation, handling spaces by encoding each word separately.\"\"\"\n",
    "    \n",
    "    return \" \".join([idna.encode(word).decode('ascii') for word in text.split()])\n",
    "    \n",
    "def punydecode(punycode: str) -> str:\n",
    "    \"\"\"Decodes a Punycode string back to UTF-8.\"\"\"\n",
    "    #return idna.decode(punycode)\n",
    "    return \" \".join([idna.decode(word) for word in punycode.split()])\n",
    "\n",
    "def process_name(name):\n",
    "    name = name.lower()\n",
    "    for n in name.split():\n",
    "        if len(n) < 2:\n",
    "            return ''\n",
    "    try:\n",
    "        return punyencode(name)\n",
    "    except:\n",
    "        #print(f'Cant convert {name}')\n",
    "        return ''\n",
    "\n",
    "dataset = open(\"data/city_names_full.txt\", 'r').read().split('\\n')\n",
    "with open('data/city_names_puny.txt', 'w') as f:\n",
    "    for n in dataset:\n",
    "        name = process_name(n)\n",
    "        if name != '':\n",
    "            f.write(name+'\\n')\n",
    "dataset = open(\"data/city_names_puny.txt\", 'r').read().split('\\n')\n",
    "puny = [x for x in dataset if 'xn--' in x]\n",
    "nopuny = [x for x in dataset if 'xn--' not in x]\n",
    "np.random.seed(42)\n",
    "dataset = [x.item() for x in np.random.choice(nopuny, 100000,replace=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c2d0da-8040-496a-aee5-76bef49da3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "charset = ['*'] + sorted(list(set([y for x in dataset for y in x])))\n",
    "ctoi = {c:i for i, c in enumerate(charset)}\n",
    "itoc = {i:c for i, c in enumerate(charset)}\n",
    "charset_size = len(charset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143beebb-1d30-4487-9c3d-895d876d8620",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(dataset: list):\n",
    "    X, Y  = [], []\n",
    "    for d in dataset:\n",
    "        example = list(d) + ['*']\n",
    "        context = [0] * context_size\n",
    "        for c in example:\n",
    "            X.append(context)\n",
    "            Y.append(ctoi[c])\n",
    "            context = context[1:] + [ctoi[c]] \n",
    "    X = torch.tensor(X)\n",
    "    Y = torch.tensor(Y)\n",
    "    return X, Y\n",
    "\n",
    "# build the dataset\n",
    "context_size = 3\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(dataset)\n",
    "n1 = int(.8 * len(dataset))  # límite para el 80% del dataset\n",
    "n2 = int(.9 * len(dataset))  # límite para el 90% del dataset\n",
    "Xtr, Ytr = build_dataset(dataset[:n1])    # 80%\n",
    "Xva, Yva = build_dataset(dataset[n1:n2])  # 10%\n",
    "Xte, Yte = build_dataset(dataset[n2:])    # 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d03b1e-ffaf-4f91-aa36-7fc0341594c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear:\n",
    "    def __init__(self, input_dim, output_dim, bias=True, generator=torch.Generator().manual_seed(42)):\n",
    "        self.W = torch.randn(input_dim, output_dim, generator=generator)/(input_dim ** 0.5)\n",
    "        self.b = torch.zeros(output_dim) if bias else None\n",
    "\n",
    "    def __call__(self, x):\n",
    "        self.out = x @ self.W\n",
    "        if self.b is not None:\n",
    "            self.out += self.b\n",
    "        return self.out\n",
    "\n",
    "    def parameters(self):\n",
    "        return [self.W] + ([] if self.b is None else [self.b])\n",
    "\n",
    "class Tanh:\n",
    "    def __call__(self, x):\n",
    "        self.out = torch.tanh(x)\n",
    "        return self.out\n",
    "\n",
    "    def parameters(self):\n",
    "        return []\n",
    "\n",
    "class BatchNorm1d:\n",
    "    def __init__(self, input_size, momentum=0.001, eps=0.0005):\n",
    "        self.momentum = momentum\n",
    "        self.eps = eps\n",
    "        self.training_mode_on = True\n",
    "        # los parametros\n",
    "        self.gamma = torch.ones(input_size)\n",
    "        self.beta = torch.zeros(input_size)\n",
    "        self.running_mean = torch.zeros(input_size)\n",
    "        self.runnint_std = torch.ones(input_size)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        if self.training_mode_on:\n",
    "            xmean = x.mean(0, keepdims=True)\n",
    "            xstd = x.std(0, keepdims=True)\n",
    "            with torch.no_grad():\n",
    "                self.running_mean = self.running_mean * (1 - self.momentum) + xmean * self.momentum\n",
    "                self.runnint_std = self.runnint_std * (1 - self.momentum) + xstd * self.momentum\n",
    "        else:\n",
    "            xmean = self.running_mean\n",
    "            xstd = self.runnint_std\n",
    "        # normalizamos x para que tenga distribución N(0, 1)\n",
    "        xhat = (x - xmean)/ (xstd + self.eps)\n",
    "        self.out = self.gamma * xhat + self.beta\n",
    "        return self.out\n",
    "\n",
    "    def parameters(self):\n",
    "        return [self.gamma, self.beta]\n",
    "\n",
    "\n",
    "class Model:\n",
    "    def __init__(self, charset_size, context_size, emb_size, hidden_size, g=torch.Generator().manual_seed(42)):\n",
    "        self.charset_size = charset_size\n",
    "        self.context_size = context_size\n",
    "        self.emb_size = emb_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.C = torch.randn(self.charset_size, self.emb_size, generator=g)\n",
    "        self.layers = [Linear(self.emb_size*self.context_size, self.hidden_size, bias=False, generator=g), BatchNorm1d(self.hidden_size), Tanh(),\n",
    "                       Linear(self.hidden_size, self.hidden_size, bias=False), BatchNorm1d(self.hidden_size), Tanh(),\n",
    "                       Linear(self.hidden_size, self.hidden_size, bias=False), BatchNorm1d(self.hidden_size), Tanh(),\n",
    "                       Linear(self.hidden_size, self.hidden_size, bias=False), BatchNorm1d(self.hidden_size), Tanh(),\n",
    "                       Linear(self.hidden_size, self.hidden_size, bias=False), BatchNorm1d(self.hidden_size), Tanh(),\n",
    "                       Linear(self.hidden_size, self.charset_size)\n",
    "                      ]\n",
    "\n",
    "        # Kaiming init para todas las capas menos la última\n",
    "        for l in self.layers[:-1]:\n",
    "            if isinstance(l, Linear):\n",
    "                l.W *= 5/3\n",
    "        self.layers[-1].W *= 0.1  # La última capa es menos confianzuda\n",
    "\n",
    "        # require_grad para todos los parámetros\n",
    "        for p in self.parameters():\n",
    "            p.requires_grad = True\n",
    "    \n",
    "    def parameters(self):\n",
    "        return [self.C] + [p for l in self.layers for p in l.parameters()]\n",
    "\n",
    "    def to(self, device):\n",
    "        for p in self.parameters():\n",
    "            p.to(device)\n",
    "\n",
    "    def count_parameters(self):\n",
    "        return sum([p.nelement() for p in self.parameters()])\n",
    "\n",
    "    def __call__(self, x):\n",
    "        self.emb = self.C[x]\n",
    "        x = self.emb.view(-1, self.emb_size*self.context_size)\n",
    "        for l in self.layers:\n",
    "            x = l(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f9802d-8b99-4cb6-b176-0931b6b4b7c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tallerLLMs]",
   "language": "python",
   "name": "conda-env-tallerLLMs-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
